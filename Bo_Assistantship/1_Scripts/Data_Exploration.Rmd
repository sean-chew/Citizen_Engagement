---
title: "Data_Exploration"
author: "Sean"
date: "1/17/2022"
output: pdf_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
### Set Environment ------------------------------------------------------------
# Clear the environment
rm(list=ls())
gc()
# So the code will compile warnings as per usual
options(warn = 0)
# Turn off scientific notation
options(scipen = 999)
### Load Packages --------------------------------------------------------------
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, magrittr, stringr, reshape2, janitor,
lubridate, readxl, data.table, ggplot2, scales, readr,
tidyr, zoo, skimr, openxlsx,ggspatial, rgeos, data.table,RColorBrewer,
tidyverse, rio, collapse, sf, glue, XML, tm, here, purrr, repurrrsive,
tmap,tidygraph, nabor,igraph, viridis, hrbrthemes,RSocrata,soql,xts,
tidycensus)
```

# Data Exploration of 311 Data

## Part 1: Exploring different agencies and setting API up:

### First Test of 311 data:


```{r}
dataset_id <- "erm2-nwe9"
api_endpoint <- paste0('https://data.cityofnewyork.us/resource/', dataset_id, '.json')
api_token <- "YRWk8RdZZ9xPMVbxc0QaHgYFU"
```
First step will be to set up our environment and begin querying using the 
socrata package. I will test 100,000 entries first.

```{r}
query_params <- soql() %>%
    soql_add_endpoint(api_endpoint) %>%
    soql_limit(100000)

query <- read.socrata(
  query_params,
  app_token = api_token
)

names(query)
agencies <- unique(query$agency)
agencies
```
### Exploring different agencies:
Because there are many agencies, I will need to dive in to see what agencies 
there are. Agencies I'm interested in include Department of Environmental 
Protection, Emergency Management, Health and Mental Hygenie, 311, and buildings
```{r}
descriptors <- function(department) {
    descriptors <- query %>% 
        filter(agency == department) %>% 
        pull(descriptor) %>% 
        unique() %>% 
        as.data.frame()
    return(descriptors)
}

agencies <- c("DOHMH","DEP","DOB","3-1-1","NYCEM")

DOHMH <- descriptors("DOHMH")
DEP <- descriptors("DEP")
DOB <- descriptors("DOB")
three11 <- descriptors("3-1-1")
NYCEM <- descriptors("NYCEM")

DOHMH
DEP
DOB
three11
NYCEM

```

Looks like 311 complains are from noise, and the only relevant agencies are DEP and potentially
NYCEM. I want to take a closer look at NYCEM before diving into DEP.
```{r}
NYCEM <- query %>% 
    filter(agency == "NYCEM") %>% 
    pull(complaint_type) %>% 
    unique() 

NYCEM

```

Looks like OEM literature requests for what to do during emergencies.
Found here, https://www1.nyc.gov/site/em/ready/guides-resources.page

My Emergency Plan is a workbook designed to help New Yorkers — especially those 
with disabilities and access and functional needs — create an emergency plan. 

This is not what we want. I will continue with DEP, querying only DEP requests.

## Part 2: Diving into DEP data:

### Pulling DEP 311 complaints:
Because there are many entries, I created an API token to not encounter throttle
limits. There are millions of entries, so I will save in a more compact data 
type, RDS. We can load this in quicker next time. The Query will be commented
out so we can query again if needed.
```{r}
## For Querying:
# DEP_params <- soql() %>%
#     soql_add_endpoint(api_endpoint) %>%
#     soql_simple_filter("agency","DEP") 
# DEP_Query <- read.socrata(
#   DEP_params,
#   app_token = api_token
# )    

# saveRDS(DEP_Query,"DEP_Data.rds")

DEP_Query <- read_rds("../3_Intermediate/DEP_Data.rds")
skim(DEP_Query)
```

### Looking at the most important complaint types:
Overall, it looks like the highest complaints are from water system, followed by
Noise, and Sewer. 
```{r}
DEP_Query_by_type <-DEP_Query %>% 
  group_by(complaint_type) %>% 
  count() %>% 
  arrange(by = n)

DEP_Query_by_type
```

### Visualizing Time Series:
Let's visualize the DEP dataset at a couple different time frames. I'm going to 
create a plotting function so we can do this quickly. From looking on aggregate,
I'm mostly interested in Air Quality, Lead, Water Conservation, Industrial 
Waste, Sewer, Water System, Asbestos, Hazardous Materials

We will do monthly and annual because daily is rather large.

```{r}

complaints <- c("Air Quality","Lead","Water Conservation","Industrial Waste",
                "Sewer","Water System","Asbestos","Hazardous Materials")

plotComplaints <- function(data,time_frame,n,complaint_type) {
  plot <- ggplot(data, aes_string(time_frame, n ,fill = complaint_type)) +
    geom_area() +
    scale_fill_viridis(discrete = T) +
    theme_minimal()  +
    xlab("2010 to Present") +
    scale_y_continuous(label=comma) +
    ggtitle(deparse(substitute(data)))
  return(plot)

}
plotline <- function(data,time_frame,n,complaint_type) {
  plot <- ggplot(data, aes_string(time_frame, n ,group = complaint_type, color = complaint_type)) +
    geom_line() +
    scale_color_viridis(discrete = T) +
    theme_minimal()  +
    xlab("2010 to Present") +
    scale_y_continuous(label=comma)+
    ggtitle(deparse(substitute(data)))
  return(plot)
}

save_plots <- function(plot){
  ggsave(paste0("../4_Outputs/",deparse(substitute(plot)),".jpg"),
         plot = plot,width = 10, height = 4)
}

# For all Complaints
DEP_time_series_all <- DEP_Query %>% 
  group_by(created_date,complaint_type) %>% 
  count() %>% 
  mutate(month = month(created_date),
         year = year(created_date)) 

DEP_monthly_all <- DEP_time_series_all %>% 
  group_by(month,year,complaint_type) %>% 
  summarise(n = sum(n)) %>% 
  mutate(plot_time = ymd(paste0(year,"-",month,"-1")),
         perc = n/sum(n)) %>% 
  filter(complaint_type %in% complaints)

DEP_annual_all <- DEP_time_series_all %>% 
  group_by(year,complaint_type) %>% 
  summarise(n = sum(n)) %>% 
  mutate(year = ymd(paste0(year,"-1-1")),
         perc = n/sum(n)) %>% 
  filter(complaint_type %in% complaints)

# Subset of complaints
DEP_time_series <- DEP_Query %>% 
  filter(complaint_type %in% complaints) %>%
  group_by(created_date,complaint_type) %>% 
  count() %>% 
  mutate(month = month(created_date),
         year = year(created_date)) 

DEP_monthly <- DEP_time_series %>% 
  group_by(month,year,complaint_type) %>% 
  summarise(n = sum(n)) %>% 
  mutate(plot_time = ymd(paste0(year,"-",month,"-1")),
         perc = n/sum(n))

DEP_annual <- DEP_monthly %>% 
  group_by(year,complaint_type) %>% 
  summarise(n = sum(n)) %>% 
  mutate(year = ymd(paste0(year,"-1-1")),
         perc = n/sum(n)) 

# Volume Plots
dep_filtered_annual_plot_volume <-plotComplaints(DEP_annual,"year","n","complaint_type")
save_plots(dep_filtered_annual_plot_volume)

dep_filtered_annual_plot_line_volume <-plotline(DEP_annual,"year","n","complaint_type")
save_plots(dep_filtered_annual_plot_line_volume)

dep_filtered_monthly_plot_volume <-plotComplaints(DEP_monthly,"plot_time","n","complaint_type")
save_plots(dep_filtered_monthly_plot_volume)

dep_filtered_monthly_plot_line_volume <-plotline(DEP_monthly,"plot_time","n","complaint_type")
save_plots(dep_filtered_monthly_plot_line_volume)

# Proportion Plots:
dep_filtered_annual_plot_perc <-plotComplaints(DEP_annual,"year","perc","complaint_type")
save_plots(dep_filtered_annual_plot_perc)

dep_filtered_monthly_plot_perc <-plotComplaints(DEP_monthly,"plot_time","perc","complaint_type")
save_plots(dep_filtered_monthly_plot_perc)

dep_annual_plot_perc <-plotComplaints(DEP_annual_all,"year","perc","complaint_type")
save_plots(dep_annual_plot_perc)

dep_monthly_plot_perc <-plotComplaints(DEP_monthly_all,"plot_time","perc","complaint_type")
save_plots(dep_monthly_plot_perc)

# Look at all plots:
dep_filtered_annual_plot_volume
dep_filtered_annual_plot_line_volume
dep_filtered_monthly_plot_volume
dep_filtered_monthly_plot_line_volume
dep_filtered_annual_plot_perc
dep_filtered_monthly_plot_perc

dep_annual_plot_perc
dep_monthly_plot_perc


```
There's definitely a seasonality to the data for the water system. Perhaps this
is due to flooding during the summer. Air quality complaints seem to have stayed
the same. We can explore the lines closer by re-running the functions with 
different values of complaint_type if needed.

### Looking at DEP complaint distribution by block and tract:
We can aggregate the complaints by census block or census tract to see where 
they are generally located. Because the data is large, we will do this on a 
sample and then expand this to all data from DEP.

#### Declare functions
```{r}
# Function for filtering complaints depending on what years and complaints we will 
# later want to visualize
complaint_filter <- function(complaints,complaint_types,level,years){
  filtered <- complaints %>%  
    st_drop_geometry %>% 
    filter(complaint_type %in% complaint_types,
           year %in% years) %>% 
    group_by(ct2010, boro_name) %>% 
    summarise(n = sum(n))
  return(filtered)
}

# Function for creating choropleth maps depending on the filtered data
complaint_mapping <- function(shapefile,filtered,output_type,years,complaints){
  
  if(length(complaints) == length(c("Air Quality","Lead","Water Conservation","Industrial Waste",
                "Sewer","Water System","Asbestos","Hazardous Materials"))){
    complaints = "All Complaints"
  } else {
    complaints = glue_collapse(complaints,", ")
  }
    ct <- shapefile %>% 
      left_join(filtered,by= c("ct2010","boro_name")) 
    map <- tm_shape(ct) +
      tm_fill("n",title="Complaints",style="quantile", palette = "viridis", lwd = .01) +
      tm_layout(main.title = paste0("NYC Complaints from \n",complaints),
                main.title.position = "center",
                main.title.size = 1,
                main.title.fontface = 2
      )
    if(output_type == "map"){
      return(map)
    }
    else if(output_type == "shape"){
      return(ct)
    }
       
    
  }
```


### Read in Data:
```{r}

# read shapefiles for census tract (New York Long Island CRS)
ct <- st_read("../2_Data/ct_2010/geo_export_1c19ce5f-d77c-4a3f-adbe-7456e4a782a6.shp") %>% 
    st_transform(crs = 2263) %>% 
    mutate(unique = paste0(boro_name,ct2010)) 

# read shapefiles for census blocks (New York Long Island CRS)
cb <- st_read("../2_Data/cb_2010/geo_export_b01427ec-0671-4e2f-b058-710f1b002026.shp") %>% 
    st_transform(crs = 2263) %>% 
    mutate(unique = paste0(boro_name,ct2010)) 

# Turn Query into SF object with points. 
# We can use this later if we need to redo it, otherwise save it for faster processing.

# DEP_points <- DEP_Query %>% 
#   filter(complaint_type %in% complaints) %>%
#   select(c("unique_key",
#            "complaint_type",
#            "created_date",
#            "x_coordinate_state_plane",
#            "y_coordinate_state_plane")) %>% 
#   drop_na() %>% 
#   st_as_sf(coords = c("x_coordinate_state_plane","y_coordinate_state_plane"),
#            crs = 2263) %>% 
#   mutate(year = year(created_date)) 
# 
# saveRDS(DEP_points,"../3_Intermediate/DEP_points.rds")

## We can use a smaller test sample size to see if our visualization is working:

DEP_points <- read_rds("../3_Intermediate/DEP_points.rds")

```

#### Test out Sample
```{r}
# sample of 10,000 to test out functions
dep_sample <- DEP_points[sample(nrow(DEP_points), 10000), ]
# spatial join to census tracts
ct_complaints <- ct %>% 
  st_intersection(dep_sample) %>% 
  group_by(ct2010,boro_name,complaint_type,year) %>% 
  count() 

# we can play around with the two inputs below:
years = c(2020:2010)
view_complaints = complaints

test<-complaint_filter(ct_complaints,view_complaints,"ct",years)
test_map<-complaint_mapping(ct,test,"ct",years,view_complaints)
```

### For the entire dataset:
Functions work for small sample, so now we can tweak those functions from above 
for the entire dataset, then break it down, by type, and by year if needed:
```{r}
years = c(2020:2010)
view_complaints = complaints
## Spatial Joins. These take extremely long, so saving for optimizing for time.

# ct_complaints_all <- ct %>% 
#   st_intersection(DEP_points) %>% 
#   group_by(ct2010,boro_name,complaint_type,year) %>% 
#   count() 
# 
# saveRDS(ct_complaints_all,"../3_Intermediate/ct_complaints_all.rds")

# cb_complaints_all <- read_rds("../3_Intermediate/cb_complaints_all.rds")
ct_complaints_all <- read_rds("../3_Intermediate/ct_complaints_all.rds")

# We can adjust input years, and input complaints as needed.
years_all = c(2020:2010)
view_complaints_all = complaints

# Filter data to what inputs we want.
complaint_filtered_ct <-complaint_filter(ct_complaints_all,view_complaints_all,"ct",years_all)

# Map all complaints, over all years.
complaint_mapping(ct,complaint_filtered_ct,"map",years_all,view_complaints)
```
### Looking at complaints by type:

```{r}

## Adjust inputs if needed:
years_all = c(2020:2010)
view_complaints_all = complaints

## Mapping 8 times, we need 8 datasets for ct and cb 
map_ct_complaints <- rep(list(ct_complaints_all),3) 

## Map over the complaints 8 times
map_complaints <- c("Air Quality",
                "Sewer","Water System")

## Input "map" 8 times
map_ct <- rep("map",3)

## For now, put in all years, 8 times.
map_years <- rep(list(years),3)

## Prepare inputs for filtering
input_ct <- list(map_ct_complaints,map_complaints,map_ct,map_years)

## Filter ct inputs.
filtered_ct_all <- pmap(input_ct,complaint_filter)

## Prepare inputs for plotting:
map_ct_shapes <- rep(list(ct),3) 

input_ct_plot <- list(map_ct_shapes,filtered_ct_all, map_ct,map_years,map_complaints)


plots_ct <- pmap(input_ct_plot,complaint_mapping)
plots_ct

plotnames = imap(complaints, ~paste0("../4_Outputs/",., ".png")) %>%
     flatten()
plotnames

# pwalk(list(plots_ct,plotnames), tmap_save)

```

## First Impressions:
Air Quality is the worst in Manhattan, with some places in queens with extremely 
high complaint levels. 

Lead complaints occur in the upper west side (yikes!) with large amounts in 
Brooklyn as well. 

Water conservation complaints occur around coastlines, and around Staten Island.

Industrial Waste occurs in some particular regions, where there probably are 
larger amounts of industrial processes (construction, near Chelsea for example)

Problem spots for the water system seem to occur in the Bronx and in Staten 
Island. 

Asbestos is the most concentrated in Manhattan and the portions of Manhattan and 
Queens that border Manhattan. 

Certain hot spots of hazardous waste occur in Statten island, lower Manhattan,
and certain areas of Queens. 

## Next Steps:
Some additional thoughts:
1) Can look at complaint channel (mobile, online, other) trends (over time, 
and distribution) - these could be indicators of access
  - Maybe we can add in socio-economic status, internet access as additional
    information?
2) Can look at the yearly change of certain complaints.
3) Can incorporate machine learning techniques to predict where future clusters 
may be held.

## Normalization Process:
### Read in Census Data:
```{r}
census_api_key("4878f9292ac0c11cddc6fabc8cd8530c4d0e12f0")

v2019 <- load_variables(2019, "acs5", cache = TRUE)

demographics <- v2019 %>% 
  filter(grepl("B02001",name))

demographics <- c(white = "B02001_002",
                  total = "B02001_001",
                  income ="B19113_001",
                  language_bad = "B16004_045",
                  language_not_well = "B16004_044",
                  native_born = "B05002_002")
Census_2019 <- 
  get_acs(
    state = 36, 
    county = c("061", "047", "081", "005", "085"), 
    geography = "tract", 
    variables = demographics,
    year = 2019
  ) %>% 
  transmute(
    cnty = str_sub(GEOID, 3, 5),
    tract = as.integer(str_sub(GEOID, 6, 12)), 
    measure = estimate, 
    boro_name = 
      case_when(
        cnty == "061" ~ "Manhattan", 
        cnty == "047" ~ "Brooklyn", 
        cnty == "081" ~ "Queens", 
        cnty == "005" ~ "Bronx", 
        cnty == "085" ~ "Staten Island"
      ), 
    ctlabel = as.character(tract / 100),
    variable = variable)

Population_2019 <- Census_2019 %>% 
  filter(variable == 'total')

census_shapes <- ct %>% 
    left_join(Population_2019, by = c("boro_name", "ctlabel"))

```
```{r}
popjoin <- function(ct,pops){
  census_shapes <- ct %>% 
    left_join(pops, by = c("boro_name", "ctlabel")) %>% 
    mutate(measure = na_if(measure,0),
           measure = na_if(measure,2),
           percapita = n/measure)
  return(census_shapes)
}
plotting_percapita <- function(ct,complaints){
  map <- tm_shape(ct) +
    tm_fill("percapita",title="Complaints",style="quantile", palette = "viridis", lwd = .01,n =10) +
    tm_layout(main.title = paste0("NYC Complaints from \n",complaints),
              main.title.position = "center",
              main.title.size = 1,
              main.title.fontface = 2)
  return(map)
}

shape_ct <- rep("shape",3)
input_ct_shapes <- list(map_ct_shapes,filtered_ct_all, shape_ct,map_years,map_complaints)
map_pop <- rep(list(Population_2019),3)
shapes_ct_all <- pmap(input_ct_shapes,complaint_mapping)
join_pop_inputs <- list(shapes_ct_all,map_pop)
ct_totalpop <- pmap(join_pop_inputs,popjoin)

percapita_inputs <-list(ct_totalpop,map_complaints)
ct_percapita_all <- pmap(percapita_inputs,plotting_percapita)
ct_percapita_all

norm_plotnames = imap(map_complaints, ~paste0("../4_Outputs/",., "_perCapita_quant_allyrs.png")) %>%
     flatten()

norm_plotnames

pwalk(list(ct_percapita_all,norm_plotnames), tmap_save)


```

```{r}
# 
# 
# ## For Querying:
# all_params <- soql() %>%
#     soql_add_endpoint(api_endpoint) %>% 
#     soql_select("unique_key, created_date, agency_name, complaint_type, descriptor, x_coordinate_state_plane,y_coordinate_state_plane") 
# 
# Query_311 <- read.socrata(
#   all_params,
#   app_token = api_token
# )
#   
# saveRDS(Query_311,"Query_311.rds")
# 
# # Turn Query into SF object with points.
# # We can use this later if we need to redo it, otherwise save it for faster processing.
# 
# Query_points <- Query_311 %>% 
#   select(c("unique_key",
#            "complaint_type",
#            "created_date",
#            "x_coordinate_state_plane",
#            "y_coordinate_state_plane")) %>%
#   drop_na() %>%
#   st_as_sf(coords = c("x_coordinate_state_plane","y_coordinate_state_plane"),
#            crs = 2263) %>%
#   mutate(year = year(created_date))
# 
# saveRDS(DEP_points,"../3_Intermediate/Query_points.rds")
# 
# ct_complaints_all <- ct %>%
#   st_intersection(Query_points) %>%
#   group_by(ct2010,boro_name,complaint_type,year) %>%
#   count()
# 
# saveRDS(ct_complaints_all,"../3_Intermediate/ct_complaints_all_agencies.rds")

```

```{r}
# DEP_points_all <- DEP_Query %>%
#   select(c("unique_key",
#            "complaint_type",
#            "created_date",
#            "x_coordinate_state_plane",
#            "y_coordinate_state_plane")) %>%
#   drop_na() %>%
#   st_as_sf(coords = c("x_coordinate_state_plane","y_coordinate_state_plane"),
#            crs = 2263) %>%
#   mutate(year = year(created_date))
# 
# saveRDS(DEP_points_all,"../3_Intermediate/DEP_points_all.rds")

## We can use a smaller test sample size to see if our visualization is working:

# DEP_points <- read_rds("../3_Intermediate/DEP_points.rds")

years = c(2020:2010)
view_complaints = map_complaints
## Spatial Joins. These take extremely long, so saving for optimizing for time.

# ct_complaints_all_1 <- ct %>%
#   st_intersection(DEP_points_all) %>%
#   group_by(ct2010,boro_name) %>%
#   count()
#  
# saveRDS(ct_complaints_all_1,"../3_Intermediate/ct_complaints_all_1.rds")

ct_complaints_all_1 <- read_rds("../3_Intermediate/ct_complaints_all_1.rds")
# Filter data to what inputs we want.

proportion_DEP <- map(filtered_ct_all,join_shapes)
proportion_input <- list(proportion_DEP,map_complaints)
proportion_DEP_all <- pmap(proportion_input,plotting_perDEP)
proportion_DEP_all
# Map all complaints, over all years.


norm_plotnames_DEP = imap(map_complaints, ~paste0("../4_Outputs/",., "_norm_DEP_quant.png")) %>%
     flatten()

norm_plotnames_DEP

pwalk(list(proportion_DEP_all,norm_plotnames_DEP), tmap_save)

plotting_perDEP <- function(ct,complaints){
  map <- tm_shape(ct) +
    tm_fill("DEP_prop",title="Complaints",style="quantile", palette = "viridis", lwd = .01) +
    tm_layout(main.title = paste0("NYC Complaints from \n",complaints),
              main.title.position = "center",
              main.title.size = 1,
              main.title.fontface = 2,
              legend.format=list(fun=function(x) paste0(formatC(x, digits=2, format="f"), " %")))
  return(map)
}
join_shapes <- function(littleshape){
  DEP_Normalized <- ct %>% 
  inner_join(ct_complaints_all_1 %>% st_drop_geometry,by = c("ct2010","boro_name")) %>% 
  rename(total = n) %>% 
  inner_join(littleshape, by =  c("ct2010","boro_name")) %>% 
  mutate(DEP_prop = n/total*100)
  return(DEP_Normalized)
}



```

